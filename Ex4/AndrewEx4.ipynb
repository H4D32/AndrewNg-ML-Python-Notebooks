{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AndrewEx4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXcK1+qEINAt0CKmfLNHzi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/H4D32/AndrewNg-ML-Python-Notebooks/blob/main/Ex4/AndrewEx4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ExCDmZXvuJ6T"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat\n",
        "import scipy.optimize as op"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat=loadmat(\"ex4data1.mat\")\n",
        "\n",
        "X=mat[\"X\"]\n",
        "y=mat[\"y\"]\n",
        "\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-j-JhXzwvMx",
        "outputId": "07bf4d4e-4a6f-4a6b-8036-6c38ae6cbaad"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 400)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mat2=loadmat(\"ex4weights.mat\")\n",
        "Theta1=mat2[\"Theta1\"] \n",
        "Theta2=mat2[\"Theta2\"] \n",
        "\n",
        "print(Theta1.shape)\n",
        "print(Theta2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-mDtwPDiJ1t",
        "outputId": "a823da07-6efd-4cc9-b273-2a1837fc5503"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25, 401)\n",
            "(10, 26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  \"\"\"\n",
        "  Compute the sigmoid of each value of z\n",
        "  \"\"\"\n",
        "\n",
        "  return 1 / (1 + np.exp(-z))"
      ],
      "metadata": {
        "id": "d1kxY95xyuvT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoidGradient(z):\n",
        "    \"\"\"\n",
        "    computes the gradient of the sigmoid function\n",
        "    \"\"\"\n",
        "    \n",
        "    sigmoid = 1/(1 + np.exp(-z))\n",
        "    \n",
        "    return sigmoid *(1-sigmoid) "
      ],
      "metadata": {
        "id": "h6w8PjMGZozo"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels,X, y,Lambda):\n",
        "\n",
        "    # Reshape nn_params back into the parameters Theta1 and Theta2, the weight matrices\n",
        "    # for our 2 layer neural network\n",
        "    Theta1 = nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
        "    Theta2 = nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
        "\n",
        "    m,n = X.shape\n",
        "    J = 0\n",
        "    Theta1_grad = np.zeros((Theta1.shape))\n",
        "    Theta2_grad = np.zeros((Theta2.shape))\n",
        "\n",
        "    X = np.hstack((np.ones((m,1)),X))\n",
        "    a1 = X\n",
        "    \n",
        "    z2 = a1 @ Theta1.T\n",
        "    a2 = sigmoid(z2)\n",
        "    a2 = np.hstack((np.ones((m,1)), a2))\n",
        "\n",
        "    z3 = a2 @ Theta2.T\n",
        "    a3 = sigmoid(z3)\n",
        "\n",
        "    h_x = a3\n",
        "    y_vec = np.zeros((m,num_labels))\n",
        "\n",
        "    for i in range(1,num_labels+1):\n",
        "        y_vec[:,i-1][:,np.newaxis] = np.where(y==i,1,0)\n",
        "    y_vec_F = y_vec.flatten()\n",
        "    h_x_F = h_x.flatten()\n",
        "\n",
        "    #J = (-y_vec(:)' * log(h_x(:)) - (1-y_vec(:))' * log(1-h_x(:)))/m\n",
        "    J = (-y_vec_F.T @ np.log(h_x_F) - (1-y_vec_F).T @ np.log(1-h_x_F))/m\n",
        "\n",
        "    newTheta1 = Theta1[:,1:].flatten()\n",
        "    newTheta2 = Theta2[:,1:].flatten()\n",
        "\n",
        "    reg_term = Lambda*((newTheta1.T @ newTheta1) + newTheta2.T @ newTheta2)\n",
        "    reg_J = J + (1/(2*m))*reg_term\n",
        "\n",
        "    for i in range(m):\n",
        "        xi= X[i,:] # 1 X 401\n",
        "        a2i = a2[i,:] # 1 X 26\n",
        "        a3i =a3[i,:] # 1 X 10\n",
        "        d3 = a3i - y_vec[i,:]\n",
        "        d2 = Theta2.T @ d3.T * sigmoidGradient(np.hstack((1,xi @ Theta1.T)))\n",
        "        Theta1_grad= Theta1_grad + d2[1:][:,np.newaxis] @ xi[:,np.newaxis].T\n",
        "        Theta2_grad = Theta2_grad + d3.T[:,np.newaxis] @ a2i[:,np.newaxis].T\n",
        "        \n",
        "    Theta1_grad = 1/m * Theta1_grad\n",
        "    Theta2_grad = 1/m*Theta2_grad\n",
        "    \n",
        "    Theta1_grad_reg = Theta1_grad + (Lambda/m) * np.hstack((np.zeros((Theta1.shape[0],1)),Theta1[:,1:]))\n",
        "    Theta2_grad_reg = Theta2_grad + (Lambda/m) * np.hstack((np.zeros((Theta2.shape[0],1)),Theta2[:,1:]))\n",
        "\n",
        "    return J, Theta1_grad, Theta2_grad, reg_J, Theta1_grad_reg, Theta2_grad_reg"
      ],
      "metadata": {
        "id": "HHH2rvr9yzoz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_layer_size  = 400\n",
        "hidden_layer_size = 25\n",
        "num_labels = 10\n",
        "nn_params = np.append(Theta1.flatten(),Theta2.flatten())\n",
        "J, Theta1_grad, Theta2_grad, reg_J, Theta1_grad_reg, Theta2_grad_reg = nnCostFunction(\n",
        "    nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, 1)\n",
        "print(\"Cost at parameters (non-regularized):\",J,\"\\nCost at parameters (Regularized):\",reg_J)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRtQKd7wePF2",
        "outputId": "7c5f183d-b465-4492-feed-db69f9ae3a3c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost at parameters (non-regularized): 0.2876291651613189 \n",
            "Cost at parameters (Regularized): 0.38376985909092365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def randInitializeWeights(L_in, L_out):\n",
        "    \"\"\"\n",
        "    randomly initializes the weights of a layer with L_in incoming connections and L_out outgoing connections.\n",
        "    Note that W should be set to a matrix of size(L_out, 1 + L_in) as\n",
        "    the first column of W handles the \"bias\" terms\n",
        "    \"\"\"\n",
        "    \n",
        "    epi = (6**1/2) / (L_in + L_out)**1/2\n",
        "    \n",
        "    W = np.random.rand(L_out,L_in +1) *(2*epi) -epi\n",
        "    \n",
        "    return W"
      ],
      "metadata": {
        "id": "ZA83FyurjCAd"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
        "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
        "initial_nn_params = np.append(initial_Theta1.flatten(),initial_Theta2.flatten())"
      ],
      "metadata": {
        "id": "u-tR91qhncuF"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nnpredict(Theta1, Theta2, X):\n",
        "    \"\"\"\n",
        "    Predict the label of an input given a trained neural network\n",
        "    \"\"\"\n",
        "    m= X.shape[0]\n",
        "    a1 = np.hstack((np.ones((m,1)),X))\n",
        "    z2 = a1 @ Theta1.T\n",
        "    a2 = sigmoid(z2)\n",
        "    a2 = np.hstack((np.ones((m,1)), a2))\n",
        "    z3 = a2 @ Theta2.T\n",
        "    a3 = sigmoid(z3)\n",
        "\n",
        "    return np.argmax(a3,axis=1)+1"
      ],
      "metadata": {
        "id": "rAqAGMEyu4y7"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradientDescentnn(X,y,initial_nn_params,alpha,num_iters,Lambda,input_layer_size, hidden_layer_size, num_labels):\n",
        "    \"\"\"\n",
        "    Take in numpy array X, y and theta and update theta by taking num_iters gradient steps\n",
        "    with learning rate of alpha\n",
        "    \n",
        "    return theta and the list of the cost of theta during each iteration\n",
        "    \"\"\"\n",
        "    Theta1 = initial_nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
        "    Theta2 = initial_nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
        "    \n",
        "    m=len(y)\n",
        "    J_history =[]\n",
        "    \n",
        "    for i in range(num_iters):\n",
        "        nn_params = np.append(Theta1.flatten(),Theta2.flatten())\n",
        "        cost, grad1, grad2 = nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels,X, y,Lambda)[3:]\n",
        "        Theta1 = Theta1 - (alpha * grad1)\n",
        "        Theta2 = Theta2 - (alpha * grad2)\n",
        "        J_history.append(cost)\n",
        "    \n",
        "    nn_paramsFinal = np.append(Theta1.flatten(),Theta2.flatten())\n",
        "    return nn_paramsFinal , J_history"
      ],
      "metadata": {
        "id": "kj3PE-z--Xvg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nnTheta, nnJ_history = gradientDescentnn(X,y,initial_nn_params,0.8,800,1,input_layer_size, hidden_layer_size, num_labels)\n",
        "Theta1 = nnTheta[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
        "Theta2 = nnTheta[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)"
      ],
      "metadata": {
        "id": "_hQfVw0DH1S_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred3 = nnpredict(Theta1, Theta2, X)\n",
        "print(\"Training Set Accuracy:\",sum(pred3[:,np.newaxis]==y)[0]/5000*100,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbC4biB-H4WF",
        "outputId": "1a21cec7-0666-420e-bb94-4b247a988897"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set Accuracy: 94.14 %\n"
          ]
        }
      ]
    }
  ]
}